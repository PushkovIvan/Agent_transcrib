{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6576f0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba7442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Привет!' additional_kwargs={} response_metadata={'token_usage': {'prompt_tokens': 14, 'completion_tokens': 4, 'total_tokens': 18, 'precached_prompt_tokens': 0}, 'model_name': 'GigaChat-2-Max:2.0.28.2', 'x_headers': {'x-request-id': '40841faf-2945-43ed-9b46-e8b215236583', 'x-session-id': 'c19e7725-f478-4b07-8075-5e5679dc23a8', 'x-client-id': None}, 'finish_reason': 'stop'} id='40841faf-2945-43ed-9b46-e8b215236583' usage_metadata={'output_tokens': 4, 'input_tokens': 14, 'total_tokens': 18, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_gigachat.chat_models import GigaChat\n",
    "\n",
    "from config import CONFIG\n",
    "\n",
    "\n",
    "giga = GigaChat(\n",
    "    # auth_url = \"https://sm-auth-sd.prom-88-89-apps.ocp-geo.ocp.sigma.sbrf.ru/api/v2/oauth\",\n",
    "    scope = 'GIGACHAT_API_CORP',\n",
    "    # Для авторизации запросов используйте ключ, полученный в проекте GigaChat API\n",
    "    credentials=CONFIG[\"token\"][\"gigachat\"],\n",
    "    verify_ssl_certs=False,\n",
    "    model = \"GigaChat-2-Max\"\n",
    ")\n",
    "messages = \"privet\"\n",
    "res = giga.invoke(messages)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbfcf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan/develop/venv/lib/python3.13/site-packages/whisper/__init__.py:69: UserWarning: /Users/ivan/.cache/whisper/large-v3.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████| 2.88G/2.88G [12:36<00:00, 4.08MiB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Whisper(\n",
       "  (encoder): AudioEncoder(\n",
       "    (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (blocks): ModuleList(\n",
       "      (0-31): 32 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TextDecoder(\n",
       "    (token_embedding): Embedding(51866, 1280)\n",
       "    (blocks): ModuleList(\n",
       "      (0-31): 32 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подгружаем модель large \n",
    "\n",
    "import whisper\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "def load_whisper_model():\n",
    "    return whisper.load_model(\"large\")\n",
    "\n",
    "load_whisper_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5454dadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan/develop/venv/lib/python3.13/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Славься, Славься, Белорусская Победа, Россия, Россия, В этом слове огонь и сила, В этом слове победы пламя. Поднимаем России знамя. Россия, Россия, В этом слове огонь и сила, В этом слове победы пламя. Поднимаем России знамя. Пусть время нас бурным потоком несёт, За нами Россия, за нами народ. Традиции святы и тысячи лет, Продолжится летопись наших побед. А если врагов налетит вороньё, Их снова Отечество встретит моё. Россия, Россия, В этом слове огонь и сила, В этом слове победы пламя. Поднимаем России знамя. Россия, Россия, В этом слове огонь и сила, В этом слове победы пламя. Поднимаем России знамя. В этом слове огонь и сила, В этом слове победы пламя. Россия, Россия, Огонь и сила, В этом слове många-bral Special Style. Россия, Россия,player- researcher. Россия, Россия,esse. Россия, российский народ. Россия, российский народ. Россия! В этом слове огонь и сила! В этом слове победы пламя! Поднимаем России знамя!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверяем модель на песне Газманова \n",
    "\n",
    "def transcribe_audio(model, audio_file):\n",
    "    # Явно указываем язык и задачу\n",
    "    result = model.transcribe(audio_file, language=\"russian\", task=\"transcribe\")\n",
    "    return result[\"text\"]\n",
    "\n",
    "transcribe_audio(model=load_whisper_model(), audio_file=\"gaz.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b6d690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
